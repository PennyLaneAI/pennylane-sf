{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial CV2 - Classification with a squeezing feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we implement the squeezing feature map together with the \"implicit\" linear classifier inspired by Schuld and Killoran (arXiv:1803.07128). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import openqml, openqml's numpy as well as an optimizer. \n",
    "\n",
    "*Note: For convenience, we use openqml's numpy library for all numpy processing. Strictly speaking, one only needs this library for numpy operations inside the cost function or functions called therein, and can use numpy imported via the usual `import numpy as np` everywhere else.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openqml as qm\n",
    "from openqml import numpy as np\n",
    "from openqml.optimize import GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The device is the StrawberryFields simulator with two quantum modes or \"wires\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qm.device('strawberryfields.fock', wires=2, cutoff_dim=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum node\n",
    "\n",
    "The variational circuit which defines the quantum node consists of two parts. First, the input is \"encoded into Hilbert space\" by a squeezing feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featuremap(x):\n",
    "\n",
    "    qm.Squeezing(1.5, x[0], [0])\n",
    "    qm.Squeezing(1.5, x[1], [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a layered circuit serves as a trainable linear classifier in Hilbert space. A single layer is defined as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(w):\n",
    "\n",
    "    qm.Beamsplitter(w[0], w[1], [0, 1])\n",
    "\n",
    "    # linear gates in quadrature\n",
    "    qm.Displacement(w[2], 0., [0])\n",
    "    qm.Displacement(w[3], 0., [1])\n",
    "\n",
    "    # quadratic gates in quadrature\n",
    "    qm.QuadraticPhase(w[4], [0])\n",
    "    qm.QuadraticPhase(w[5], [1])\n",
    "\n",
    "    # cubic gates in quadrature\n",
    "    qm.CubicPhase(w[6], [0])\n",
    "    qm.CubicPhase(w[7], [1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variational circuit in the quantum node first encodes the input via the feature map and then executes the layers. The output is the expectation of the photon number in the first mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qm.qnode(dev)\n",
    "def qclassifier(weights, x=None):\n",
    "\n",
    "    # execute feature map\n",
    "    featuremap(x)\n",
    "\n",
    "    # execute linear classifier\n",
    "    for w in weights:\n",
    "        layer(w)\n",
    "\n",
    "    return qm.expval.PhotonNumber(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an objective we take the square loss between target labels and model predictions. To check the quality of the classifier, we also define the accuracy, or the share of correctly classified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss += (l-p)**2\n",
    "    loss = loss/len(labels)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def accuracy(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l-p) < 1e-5:\n",
    "            loss += 1\n",
    "    loss = loss/len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cost function we compute the outputs from the variational circuit and compute the square loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, X, Y):\n",
    "\n",
    "    outpts = [qclassifier(weights, x=x) for x in X]\n",
    "\n",
    "    loss = square_loss(Y, outpts)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load data samples from the moons data set and split it into a training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load function data\n",
    "data = np.loadtxt(\"moons.txt\")\n",
    "X = data[:, 0:2]\n",
    "Y = data[:, -1]\n",
    "\n",
    "# split into training and validation set\n",
    "num_data = len(Y)\n",
    "num_train = int(0.5*num_data)\n",
    "index = np.random.permutation(range(num_data))\n",
    "X_train = X[index[: num_train]]\n",
    "Y_train = Y[index[: num_train]]\n",
    "X_val = X[index[num_train: ]]\n",
    "Y_val = Y[index[num_train: ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data.\n",
    "\n",
    "*Note: For the next cell to work you need python's matplotlib library.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_train[:,0][Y_train==0], X_train[:,1][Y_train==0], marker='o', color='green', label='train 0')\n",
    "plt.scatter(X_val[:,0][Y_val==0], X_val[:,1][Y_val==0], marker='^', color='green', label='validation 0')\n",
    "plt.scatter(X_train[:,0][Y_train==1], X_train[:,1][Y_train==1], marker='^', color='purple', label='train 1')\n",
    "plt.scatter(X_val[:,0][Y_val==1], X_val[:,1][Y_val==1], marker='o', color='purple', label='validation 1')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trainable circuit parameters (called variables in PennyLane), are initialized with values sampled from a normal distribution. We use 4 layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00780016, -0.01318971, -0.05528023, -0.00926701,  0.00967461,\n",
       "         0.12300161, -0.02517163, -0.00559375],\n",
       "       [ 0.11062958, -0.00276368, -0.04096286,  0.00378923,  0.02925287,\n",
       "         0.02757426, -0.05036169,  0.0263325 ],\n",
       "       [-0.05517909, -0.0095554 ,  0.00525995, -0.02626185,  0.10255129,\n",
       "        -0.03813769, -0.0121489 ,  0.00324524],\n",
       "       [-0.00085168,  0.09182423, -0.02822648,  0.04603324,  0.01946975,\n",
       "         0.04737105, -0.05361193, -0.01559399]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize weights\n",
    "num_layers = 4\n",
    "vars_init = 0.05*np.random.randn(num_layers, 8)\n",
    "\n",
    "vars_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the Adam optimizer and update the weights for 50 steps with a batch size of 5. In every step the accuracy is computed for the entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Cost: 0.2109074 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     2 | Cost: 0.2387016 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     3 | Cost: 0.2817764 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     4 | Cost: 0.2949667 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     5 | Cost: 0.2803269 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     6 | Cost: 0.3037542 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     7 | Cost: 0.3655550 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     8 | Cost: 0.3101475 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:     9 | Cost: 0.2318217 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    10 | Cost: 0.1770130 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    11 | Cost: 0.2350665 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    12 | Cost: 0.2889203 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    13 | Cost: 0.2115410 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    14 | Cost: 0.2317330 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    15 | Cost: 0.2685794 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    16 | Cost: 0.2074138 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    17 | Cost: 0.2342268 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    18 | Cost: 0.3234120 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    19 | Cost: 0.1627600 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    20 | Cost: 0.2797280 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    21 | Cost: 0.2839054 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    22 | Cost: 0.2989161 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    23 | Cost: 0.2861933 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    24 | Cost: 0.2311454 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    25 | Cost: 0.2984466 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    26 | Cost: 0.2574613 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    27 | Cost: 0.2627394 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    28 | Cost: 0.1990287 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    29 | Cost: 0.1426422 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    30 | Cost: 0.3170344 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    31 | Cost: 0.2310662 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    32 | Cost: 0.1737352 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    33 | Cost: 0.3512313 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    34 | Cost: 0.2376604 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    35 | Cost: 0.2135939 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    36 | Cost: 0.1541114 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    37 | Cost: 0.3502659 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    38 | Cost: 0.2560774 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    39 | Cost: 0.1923265 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    40 | Cost: 0.2372100 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    41 | Cost: 0.2343026 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    42 | Cost: 0.3615974 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    43 | Cost: 0.4459387 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    44 | Cost: 0.1479332 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    45 | Cost: 0.2375685 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    46 | Cost: 0.1897477 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    47 | Cost: 0.2635259 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    48 | Cost: 0.2530429 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    49 | Cost: 0.1855287 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n",
      "Iter:    50 | Cost: 0.2477282 | Acc train: 0.5200000 | Acc validation: 0.6200000 \n"
     ]
    }
   ],
   "source": [
    "o = GradientDescentOptimizer(0.0001)\n",
    "\n",
    "\n",
    "batch_size = 5\n",
    "vars = vars_init\n",
    "for it in range(50):\n",
    "\n",
    "    # select minibatch of training samples\n",
    "    batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "    X_train_batch = X_train[batch_index]\n",
    "    Y_train_batch = Y_train[batch_index]\n",
    "\n",
    "    vars = o.step(lambda v: cost(v, X_train_batch, Y_train_batch), vars)\n",
    "\n",
    "    # Compute predictions on train and validation set\n",
    "    pred_train = [np.round(qclassifier(vars, x=x_)) for x_ in X_train]\n",
    "    pred_val = [np.round(qclassifier(vars, x=x_)) for x_ in X_val]\n",
    "    acc_train = accuracy(Y_train, pred_train)\n",
    "    acc_val = accuracy(Y_val, pred_val)\n",
    "\n",
    "    print(\"Iter: {:5d} | Cost: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "          \"\".format(it+1, cost(vars, X_train_batch, Y_train_batch), acc_train, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the last predictions we can plot the classification of the model for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X_train[:,0][pred_train==0], X_train[:,1][pred_train==0], marker='o', color='green', label='train 0')\n",
    "plt.scatter(X_val[:,0][pred_val==0], X_val[:,1][pred_val==0], marker='^', color='green', label='validation 0')\n",
    "plt.scatter(X_train[:,0][pred_train==1], X_train[:,1][pred_train==1], marker='^', color='purple', label='train 1')\n",
    "plt.scatter(X_val[:,0][pred_val==1], X_val[:,1][pred_val==1], marker='o', color='purple', label='validation 1')\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
